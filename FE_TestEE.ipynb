{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## 1개변수 임베딩 ##############################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터갯수 32, 인풋길이 10\n",
    "# y는 바이너리\n",
    "x = pd.DataFrame(np.random.randint(1000, size=(32, 10)))\n",
    "y = pd.DataFrame(np.random.randint(2, size=32))\n",
    "x.columns = ['v'+ str(i).zfill(2) for i in range(0,10)]\n",
    "\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Reshape, Concatenate, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 단어 10개로 만들어진 문장을 입력함. 단어사전은 1000개 단어의 집합\n",
    "input_layer = Input(shape=(10,))\n",
    "emb_layer = Embedding(1000, 7, input_length=10, name = 'emb_test')(input_layer)\n",
    "emb_layer = Flatten()(emb_layer)\n",
    "output_layer = Dense(32, activation=\"relu\")(emb_layer)\n",
    "output_layer = Dense(16, activation=\"relu\")(output_layer)\n",
    "output_layer = Dense(1, activation=\"sigmoid\")(output_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "model.fit(x,y,epochs=10, verbose=0)\n",
    "\n",
    "# 임베딩 결과물 가져오기\n",
    "# 1000개의 단어들을 7차원으로 표현.  \n",
    "w = pd.DataFrame(model.get_layer('emb_test').get_weights()[0], columns=['ee_'+ str(i).zfill(2) for i in range(0, 7)])\n",
    "#print(np.array(w).shape, '\\n', w,'\\n', w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매핑테이블 만듬\n",
    "unique_Status = np.sort(range(0,1000)) # 단어 0~999까지\n",
    "mapping = pd.DataFrame(unique_Status, columns=['word'])\n",
    "\n",
    "# ee 가중치와 조인, csv 저장\n",
    "eeTable = pd.concat([mapping, w], axis=1)\n",
    "eeTable.to_csv('D:\\\\testEE.csv', index=False)\n",
    "\n",
    "# 임베딩 파일 로딩\n",
    "eeTableLoaded = pd.read_csv('D:\\\\testEE.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     word     ee_00     ee_01     ee_02     ee_03     ee_04     ee_05  \\\n",
       "0       0  0.034359 -0.031802  0.011089 -0.006146 -0.006652 -0.031881   \n",
       "1       1  0.045106 -0.003110  0.043820 -0.007295  0.021692 -0.006928   \n",
       "2       2  0.040626 -0.018116  0.003220  0.046908  0.008734 -0.004893   \n",
       "3       3  0.017488 -0.035649  0.044704 -0.027811  0.001796 -0.013830   \n",
       "4       4 -0.043958 -0.045626  0.036492 -0.032439 -0.020348  0.002276   \n",
       "..    ...       ...       ...       ...       ...       ...       ...   \n",
       "995   995 -0.033385 -0.042919  0.000308 -0.041362 -0.039529  0.017479   \n",
       "996   996  0.037930 -0.001746 -0.032050 -0.047751  0.033170 -0.034298   \n",
       "997   997  0.034663  0.047013 -0.046163 -0.043144  0.039405  0.019645   \n",
       "998   998  0.021262 -0.012744  0.044078 -0.036168  0.001413 -0.012129   \n",
       "999   999 -0.001942 -0.060085  0.028484 -0.018518  0.051576  0.036302   \n",
       "\n",
       "        ee_06  \n",
       "0   -0.045299  \n",
       "1    0.042159  \n",
       "2   -0.012587  \n",
       "3    0.048634  \n",
       "4   -0.026732  \n",
       "..        ...  \n",
       "995 -0.042797  \n",
       "996  0.036132  \n",
       "997  0.043322  \n",
       "998  0.042502  \n",
       "999  0.009731  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>ee_00</th>\n      <th>ee_01</th>\n      <th>ee_02</th>\n      <th>ee_03</th>\n      <th>ee_04</th>\n      <th>ee_05</th>\n      <th>ee_06</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.034359</td>\n      <td>-0.031802</td>\n      <td>0.011089</td>\n      <td>-0.006146</td>\n      <td>-0.006652</td>\n      <td>-0.031881</td>\n      <td>-0.045299</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.045106</td>\n      <td>-0.003110</td>\n      <td>0.043820</td>\n      <td>-0.007295</td>\n      <td>0.021692</td>\n      <td>-0.006928</td>\n      <td>0.042159</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.040626</td>\n      <td>-0.018116</td>\n      <td>0.003220</td>\n      <td>0.046908</td>\n      <td>0.008734</td>\n      <td>-0.004893</td>\n      <td>-0.012587</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.017488</td>\n      <td>-0.035649</td>\n      <td>0.044704</td>\n      <td>-0.027811</td>\n      <td>0.001796</td>\n      <td>-0.013830</td>\n      <td>0.048634</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>-0.043958</td>\n      <td>-0.045626</td>\n      <td>0.036492</td>\n      <td>-0.032439</td>\n      <td>-0.020348</td>\n      <td>0.002276</td>\n      <td>-0.026732</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>995</td>\n      <td>-0.033385</td>\n      <td>-0.042919</td>\n      <td>0.000308</td>\n      <td>-0.041362</td>\n      <td>-0.039529</td>\n      <td>0.017479</td>\n      <td>-0.042797</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>996</td>\n      <td>0.037930</td>\n      <td>-0.001746</td>\n      <td>-0.032050</td>\n      <td>-0.047751</td>\n      <td>0.033170</td>\n      <td>-0.034298</td>\n      <td>0.036132</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>997</td>\n      <td>0.034663</td>\n      <td>0.047013</td>\n      <td>-0.046163</td>\n      <td>-0.043144</td>\n      <td>0.039405</td>\n      <td>0.019645</td>\n      <td>0.043322</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>998</td>\n      <td>0.021262</td>\n      <td>-0.012744</td>\n      <td>0.044078</td>\n      <td>-0.036168</td>\n      <td>0.001413</td>\n      <td>-0.012129</td>\n      <td>0.042502</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>999</td>\n      <td>-0.001942</td>\n      <td>-0.060085</td>\n      <td>0.028484</td>\n      <td>-0.018518</td>\n      <td>0.051576</td>\n      <td>0.036302</td>\n      <td>0.009731</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "eeTableLoaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 임베딩 결과 붙이기\n",
    "def append_emb(df, emb, emb_name):\n",
    "    df_new = pd.merge(df, emb, on=emb_name, how='left')\n",
    "    last_col = df_new.shape[1] - 1\n",
    "    assert pd.Series(df_new.iloc[:, last_col:].values.flatten()).isnull().sum() == 0  # confirm all df records matched to an embedding vector\n",
    "    return df_new\n",
    "\n",
    "append_emb(x, eeTableLoaded, '0', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     key\n",
       "0      0\n",
       "1      1\n",
       "2      2\n",
       "3      3\n",
       "4      4\n",
       "..   ...\n",
       "995  995\n",
       "996  996\n",
       "997  997\n",
       "998  998\n",
       "999  999\n",
       "\n",
       "[1000 rows x 1 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>key</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>995</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>996</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>997</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>998</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>999</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 매핑 - 인덱스 결합\n",
    "pd.concat([mapping, weights], axis=1) #  weight 가져옴\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######## New Test : 데이터 2개로 해보기 ################################################\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "x1 = np.random.randint(1000, size=32)\n",
    "x2 = np.random.randint(500, size=32)\n",
    "x_concat = pd.concat([pd.Series(x1), pd.Series(x2)], axis=1)\n",
    "\n",
    "y = pd.Series(np.random.randint(2, size=32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Dense, Reshape, Concatenate, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_layer_1 = Input(shape=[1])\n",
    "input_layer_2 = Input(shape=[1])\n",
    "\n",
    "emb_layer_1 = Embedding(1000, 5, input_length=1, name='emb_1')(input_layer_1)\n",
    "emb_layer_1 = Flatten()(emb_layer_1)\n",
    "\n",
    "emb_layer_2 = Embedding(500, 3, input_length=1, name='emb_2')(input_layer_2)\n",
    "emb_layer_2 = Flatten()(emb_layer_2)\n",
    "\n",
    "output_layer = Concatenate(name = 'concate_emb')([emb_layer_1, emb_layer_2])\n",
    "output_layer = Dense(32, activation='relu')(output_layer)\n",
    "output_layer = Dense(16, activation='relu')(output_layer)\n",
    "output_layer = Dense(1, activation='sigmoid')(output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "emb_1 (Embedding)               (None, 1, 5)         5000        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "emb_2 (Embedding)               (None, 1, 3)         1500        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 5)            0           emb_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 3)            0           emb_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concate_emb (Concatenate)       (None, 8)            0           flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32)           288         concate_emb[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           528         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            17          dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 7,333\n",
      "Trainable params: 7,333\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6926\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6924\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6922\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6920\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6918\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6916\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6914\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6912\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6911\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6909\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29026c36d68>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "model = Model(inputs=[input_layer_1, input_layer_2], outputs=output_layer)\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy')\n",
    "model.summary()\n",
    "\n",
    "model.fit([x1, x2], y, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1000, 5) (500, 3) \n\n            0         1         2         3         4\n0    0.048499  0.041596  0.013411 -0.035943 -0.048730\n1   -0.033168  0.030140 -0.011766  0.008337  0.039782\n2   -0.034977 -0.010011  0.028479  0.017290  0.003450\n3   -0.042601  0.044423 -0.025449 -0.038999  0.046707\n4   -0.009436  0.037096 -0.044556 -0.040064 -0.012146\n..        ...       ...       ...       ...       ...\n995  0.040788  0.029617 -0.040700 -0.013995 -0.025342\n996 -0.023819 -0.004727 -0.025862 -0.010402  0.049300\n997  0.030392  0.011923 -0.007644 -0.015188  0.020712\n998  0.043034  0.039772  0.023720 -0.026079  0.012737\n999  0.015894 -0.025313 -0.003690  0.021829 -0.001586\n\n[1000 rows x 5 columns] \n             0         1         2\n0    0.008769 -0.049025 -0.022256\n1    0.004049 -0.010723  0.018596\n2    0.044816  0.019207  0.040492\n3    0.005513  0.035920  0.036377\n4    0.008368  0.038584 -0.026751\n..        ...       ...       ...\n495  0.036175  0.000583 -0.036869\n496  0.024110  0.002484 -0.021499\n497 -0.029204 -0.021686 -0.035988\n498  0.010763  0.028044 -0.030726\n499  0.043575  0.045968  0.028006\n\n[500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "w1 = pd.DataFrame(model.get_layer('emb_1').get_weights()[0])\n",
    "w2 = pd.DataFrame(model.get_layer('emb_2').get_weights()[0])\n",
    "w1.to_csv('emb1.csv', index=False, header=False)\n",
    "w2.to_csv('emb2.csv', index=False, header=False)\n",
    "\n",
    "print(np.array(w1).shape, np.array(w2).shape, '\\n')\n",
    "print(w1, '\\n', w2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}